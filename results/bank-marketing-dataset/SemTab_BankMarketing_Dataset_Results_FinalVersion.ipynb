{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a31d496d56549b4bd280cc84b859528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17f8700bd58042f281ecedc2d659679a",
              "IPY_MODEL_6c00769c5f7443199462453060f87c74",
              "IPY_MODEL_889f802c0caa4e15a3ab9543606ed865"
            ],
            "layout": "IPY_MODEL_0f8701b9bdca4ad9a58171ec7d29c35e"
          }
        },
        "17f8700bd58042f281ecedc2d659679a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87d8628bcbf247fb9d4ede210834669b",
            "placeholder": "​",
            "style": "IPY_MODEL_02ce021a5b7a4100bd3a017d497f37da",
            "value": "Batches: 100%"
          }
        },
        "6c00769c5f7443199462453060f87c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed10ee3455b4f52952139185c1f1a1c",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_558e0602834e4f01891bb916b32b590c",
            "value": 15
          }
        },
        "889f802c0caa4e15a3ab9543606ed865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b27e94d753495c9a82d96698bced11",
            "placeholder": "​",
            "style": "IPY_MODEL_1f93be00f7f94a3da9b60e296a93613f",
            "value": " 15/15 [00:00&lt;00:00, 46.04it/s]"
          }
        },
        "0f8701b9bdca4ad9a58171ec7d29c35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d8628bcbf247fb9d4ede210834669b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ce021a5b7a4100bd3a017d497f37da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ed10ee3455b4f52952139185c1f1a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558e0602834e4f01891bb916b32b590c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03b27e94d753495c9a82d96698bced11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f93be00f7f94a3da9b60e296a93613f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c76a97423b6f4041a45cf6df61b416c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb926741b94d47ac891510994fa8c71a",
              "IPY_MODEL_5622041080c8460ebc87eb4e87fa4c1a",
              "IPY_MODEL_b19ad18a41f74b9a90a041f5468fb23d"
            ],
            "layout": "IPY_MODEL_5d0b4500d01443af9eb1e20d49e55eb8"
          }
        },
        "eb926741b94d47ac891510994fa8c71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab8f87e79e74bfab085865fa716ce9f",
            "placeholder": "​",
            "style": "IPY_MODEL_fbd449606d53462bba6bbee4885925ac",
            "value": "Batches: 100%"
          }
        },
        "5622041080c8460ebc87eb4e87fa4c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c8333a16bc44d48957a31e34bfee640",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_252ca6102cb247df94f92d66772d4210",
            "value": 33
          }
        },
        "b19ad18a41f74b9a90a041f5468fb23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d848f07d97469aadeae97bcd83252b",
            "placeholder": "​",
            "style": "IPY_MODEL_c09006aea3374afdb4ad04e6a502d52f",
            "value": " 33/33 [00:00&lt;00:00, 77.77it/s]"
          }
        },
        "5d0b4500d01443af9eb1e20d49e55eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab8f87e79e74bfab085865fa716ce9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd449606d53462bba6bbee4885925ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c8333a16bc44d48957a31e34bfee640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252ca6102cb247df94f92d66772d4210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45d848f07d97469aadeae97bcd83252b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09006aea3374afdb4ad04e6a502d52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92d6ecde684d42fcbee3713c4c174fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd3e14bea8554e8b80a9bc34cb3a9b56",
              "IPY_MODEL_0c76a52713504a1ba6907572f3f3dd18",
              "IPY_MODEL_98952d4d9669422fbb8acefc60d21a88"
            ],
            "layout": "IPY_MODEL_17cd6de8f64147edb9b4c048edf026c2"
          }
        },
        "dd3e14bea8554e8b80a9bc34cb3a9b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55891c2260cc4057acc704843755c9eb",
            "placeholder": "​",
            "style": "IPY_MODEL_1560546497ca49ff9d4083bcfe579153",
            "value": "Batches: 100%"
          }
        },
        "0c76a52713504a1ba6907572f3f3dd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_998c71ca0bd44e0282209713902b936f",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ebbd9157e3441f897fd2cd59506837e",
            "value": 15
          }
        },
        "98952d4d9669422fbb8acefc60d21a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a62155068d73424eb6a65f2299a85b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_4be76db68b4645aca6d01744d1138ed3",
            "value": " 15/15 [00:00&lt;00:00, 64.35it/s]"
          }
        },
        "17cd6de8f64147edb9b4c048edf026c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55891c2260cc4057acc704843755c9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1560546497ca49ff9d4083bcfe579153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "998c71ca0bd44e0282209713902b936f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebbd9157e3441f897fd2cd59506837e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a62155068d73424eb6a65f2299a85b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be76db68b4645aca6d01744d1138ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE8r5uy07SZa",
        "outputId": "49d64885-eff8-4b42-f2e7-d4bb2ab99184"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m194.6/275.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=4d34dd7b739b141c22a175fcd77e87892c4138e84f09851d0df68d3b144f0a05\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Code\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FixedSemTabVsOffShelfLLMs:\n",
        "    def __init__(self):\n",
        "        self.label_encoders = {}\n",
        "        print(\"Loading SemTab components...\")\n",
        "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "        try:\n",
        "            from transformers import pipeline\n",
        "            print(\"Loading DistilGPT2 for SemTab...\")\n",
        "            self.llm = pipeline('text-generation',\n",
        "                               model='distilgpt2',\n",
        "                               max_length=80,\n",
        "                               do_sample=True,\n",
        "                               temperature=0.5,\n",
        "                               pad_token_id=50256)\n",
        "            print(\"DistilGPT2 loaded for SemTab!\")\n",
        "            self.use_llm = True\n",
        "        except Exception as e:\n",
        "            print(f\"LLM loading failed: {e}\")\n",
        "            self.use_llm = False\n",
        "\n",
        "        self.off_shelf_llms = {}\n",
        "        self.load_off_shelf_llms()\n",
        "\n",
        "        print(\"Fixed SemTab vs Off-the-Shelf LLMs Framework ready!\")\n",
        "\n",
        "    def load_off_shelf_llms(self):\n",
        "        from transformers import pipeline\n",
        "\n",
        "        llm_configs = {\n",
        "            'DistilBERT': {\n",
        "                'model': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
        "                'task': 'text-classification'\n",
        "            },\n",
        "            'DistilGPT2': {\n",
        "                'model': 'distilgpt2',\n",
        "                'task': 'text-generation'\n",
        "            },\n",
        "            'OPT-125M': {\n",
        "                'model': 'facebook/opt-125m',\n",
        "                'task': 'text-generation'\n",
        "            },\n",
        "            'GPT2-Small': {\n",
        "                'model': 'gpt2',\n",
        "                'task': 'text-generation'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for name, config in llm_configs.items():\n",
        "            try:\n",
        "                print(f\"Loading {name}...\")\n",
        "                if config['task'] == 'text-classification':\n",
        "                    llm = pipeline(config['task'], model=config['model'], return_all_scores=True)\n",
        "                else:\n",
        "                    llm = pipeline(config['task'], model=config['model'],\n",
        "                                  max_length=70, do_sample=True, temperature=0.6,\n",
        "                                  pad_token_id=50256)\n",
        "                self.off_shelf_llms[name] = {'pipeline': llm, 'task': config['task']}\n",
        "                print(f\"{name} loaded successfully!\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {name}: {e}\")\n",
        "                self.off_shelf_llms[name] = {'pipeline': None, 'task': 'failed'}\n",
        "\n",
        "    def create_focused_narrative(self, row):\n",
        "        age_desc = \"young\" if row['age'] < 30 else \"senior\" if row['age'] > 60 else \"middle-aged\"\n",
        "\n",
        "        narrative = f\"{age_desc} {row['marital']} {row['job']} with {row['education']}\"\n",
        "\n",
        "        if row['housing'] == 'yes' and row['loan'] == 'yes':\n",
        "            narrative += \", multiple loans\"\n",
        "        elif row['housing'] == 'yes':\n",
        "            narrative += \", homeowner with mortgage\"\n",
        "        elif row['loan'] == 'yes':\n",
        "            narrative += \", has personal loan\"\n",
        "        else:\n",
        "            narrative += \", debt-free\"\n",
        "\n",
        "        if row['duration'] > 400:\n",
        "            narrative += f\", very engaged {row['duration']}s call\"\n",
        "        elif row['duration'] > 200:\n",
        "            narrative += f\", engaged {row['duration']}s call\"\n",
        "        else:\n",
        "            narrative += f\", brief {row['duration']}s call\"\n",
        "\n",
        "        narrative += f\" via {row['contact']}\"\n",
        "\n",
        "        if row['previous'] > 0:\n",
        "            if row['poutcome'] == 'success':\n",
        "                narrative += f\", {row['previous']} prior wins\"\n",
        "            elif row['poutcome'] == 'failure':\n",
        "                narrative += f\", {row['previous']} prior losses\"\n",
        "\n",
        "        return narrative\n",
        "\n",
        "    def enhance_narrative_aggressively(self, narrative):\n",
        "        if not self.use_llm:\n",
        "            return narrative\n",
        "\n",
        "        try:\n",
        "            prompt = f\"Customer: {narrative}. Likely to subscribe:\"\n",
        "            result = self.llm(prompt, max_new_tokens=8, num_return_sequences=1)\n",
        "            llm_text = result[0]['generated_text']\n",
        "            enhancement = llm_text.replace(prompt, \"\").strip()\n",
        "\n",
        "            if len(enhancement) > 3 and len(enhancement) < 25:\n",
        "                clean_enhancement = enhancement.split('.')[0].strip()\n",
        "                if len(clean_enhancement) > 3:\n",
        "                    return f\"{narrative}. {clean_enhancement}\"\n",
        "\n",
        "            return narrative\n",
        "        except:\n",
        "            return narrative\n",
        "\n",
        "    def predict_with_off_shelf_llm(self, narratives, llm_name):\n",
        "        if llm_name not in self.off_shelf_llms or self.off_shelf_llms[llm_name]['pipeline'] is None:\n",
        "            return np.random.choice([0, 1], len(narratives), p=[0.885, 0.115])\n",
        "\n",
        "        llm_info = self.off_shelf_llms[llm_name]\n",
        "        llm = llm_info['pipeline']\n",
        "        task = llm_info['task']\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        print(f\"Running {llm_name} predictions...\")\n",
        "        for i, narrative in enumerate(narratives):\n",
        "            if i % 100 == 0:\n",
        "                print(f\"{llm_name} Progress: {i}/{len(narratives)}\")\n",
        "\n",
        "            try:\n",
        "                if task == 'text-classification':\n",
        "                    prompt = f\"Will subscribe to term deposit: {narrative}\"\n",
        "                    result = llm(prompt)\n",
        "                    positive_score = result[0]['score'] if result[0]['label'] == 'POSITIVE' else result[1]['score']\n",
        "                    prediction = 1 if positive_score > 0.5 else 0\n",
        "\n",
        "                elif task == 'text-generation':\n",
        "                    prompt = f\"Customer: {narrative}. Subscribe? Yes/No:\"\n",
        "                    result = llm(prompt, max_new_tokens=3, num_return_sequences=1)\n",
        "                    output = result[0]['generated_text'].replace(prompt, \"\").strip().lower()\n",
        "\n",
        "                    if any(pos_word in output for pos_word in ['yes', 'likely', 'subscribe', 'will']):\n",
        "                        prediction = 1\n",
        "                    elif any(neg_word in output for neg_word in ['no', 'unlikely', 'won\\'t']):\n",
        "                        prediction = 0\n",
        "                    else:\n",
        "                        positive_signals = sum(1 for word in ['engaged', 'university', 'management', 'debt-free', 'wins'] if word in narrative.lower())\n",
        "                        negative_signals = sum(1 for word in ['brief', 'loans', 'losses', 'unemployed'] if word in narrative.lower())\n",
        "                        prediction = 1 if positive_signals > negative_signals else 0\n",
        "\n",
        "                predictions.append(prediction)\n",
        "\n",
        "            except:\n",
        "                prediction = np.random.choice([0, 1], p=[0.885, 0.115])\n",
        "                predictions.append(prediction)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def generate_optimized_semtab_features(self, df):\n",
        "        print(f\"Creating optimized SemTab features for {len(df)} samples...\")\n",
        "\n",
        "        narratives = []\n",
        "        for idx, (_, row) in enumerate(df.iterrows()):\n",
        "            if idx % 300 == 0:\n",
        "                print(f\"SemTab Progress: {idx}/{len(df)}\")\n",
        "\n",
        "            narrative = self.create_focused_narrative(row)\n",
        "\n",
        "            if self.use_llm and np.random.random() < 0.5:\n",
        "                narrative = self.enhance_narrative_aggressively(narrative)\n",
        "\n",
        "            narratives.append(narrative)\n",
        "\n",
        "        print(\"Converting to embeddings...\")\n",
        "        embeddings = self.embedding_model.encode(narratives, show_progress_bar=True)\n",
        "\n",
        "        from sklearn.decomposition import PCA\n",
        "        pca = PCA(n_components=10)\n",
        "        reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "        semantic_df = pd.DataFrame(reduced_embeddings, columns=[f'sem_{i}' for i in range(10)])\n",
        "\n",
        "        phrase_features = []\n",
        "        for narrative in narratives:\n",
        "            features = {\n",
        "                'very_engaged': 1 if 'very engaged' in narrative else 0,\n",
        "                'debt_free': 1 if 'debt-free' in narrative else 0,\n",
        "                'multiple_loans': 1 if 'multiple loans' in narrative else 0,\n",
        "                'prior_wins': 1 if 'prior wins' in narrative else 0,\n",
        "                'prior_losses': 1 if 'prior losses' in narrative else 0,\n",
        "                'university_educated': 1 if 'university' in narrative else 0,\n",
        "                'professional_job': 1 if any(job in narrative for job in ['management', 'admin', 'technician']) else 0,\n",
        "                'homeowner': 1 if 'homeowner' in narrative else 0\n",
        "            }\n",
        "            phrase_features.append(features)\n",
        "\n",
        "        phrase_df = pd.DataFrame(phrase_features)\n",
        "        final_features = pd.concat([semantic_df, phrase_df], axis=1)\n",
        "\n",
        "        return final_features, narratives\n",
        "\n",
        "    def prepare_classical_features(self, df, is_training=True):\n",
        "        df_copy = df.copy()\n",
        "\n",
        "        categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan',\n",
        "                           'contact', 'month', 'poutcome']\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            if col in df_copy.columns:\n",
        "                if is_training:\n",
        "                    self.label_encoders[col] = LabelEncoder()\n",
        "                    df_copy[col] = self.label_encoders[col].fit_transform(df_copy[col].astype(str))\n",
        "                else:\n",
        "                    if col in self.label_encoders:\n",
        "                        unknown_mask = ~df_copy[col].astype(str).isin(self.label_encoders[col].classes_)\n",
        "                        if unknown_mask.any():\n",
        "                            df_copy.loc[unknown_mask, col] = self.label_encoders[col].classes_[0]\n",
        "                        df_copy[col] = self.label_encoders[col].transform(df_copy[col].astype(str))\n",
        "\n",
        "        return df_copy\n",
        "\n",
        "    def explain_semtab_with_lime(self, model, X_test, feature_names, narratives, y_test, predictions, sample_indices=[0, 1, 2]):\n",
        "        try:\n",
        "            from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "            print(\"\\nLIME Interpretability Analysis\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            explainer = LimeTabularExplainer(\n",
        "                X_test.values,\n",
        "                feature_names=feature_names,\n",
        "                class_names=['Not Subscribe', 'Subscribe'],\n",
        "                mode='classification',\n",
        "                discretize_continuous=True\n",
        "            )\n",
        "\n",
        "            for i, idx in enumerate(sample_indices):\n",
        "                if idx < len(X_test):\n",
        "                    print(f\"\\nSample {i+1} LIME Explanation:\")\n",
        "                    print(f\"Narrative: {narratives[idx]}\")\n",
        "                    print(f\"Actual: {'Subscribe' if y_test.iloc[idx] == 1 else 'Not Subscribe'}\")\n",
        "                    print(f\"Predicted: {'Subscribe' if predictions[idx] == 1 else 'Not Subscribe'}\")\n",
        "\n",
        "                    explanation = explainer.explain_instance(\n",
        "                        X_test.iloc[idx].values,\n",
        "                        model.predict_proba,\n",
        "                        num_features=6\n",
        "                    )\n",
        "\n",
        "                    semantic_features = []\n",
        "                    phrase_features = []\n",
        "                    classical_features = []\n",
        "\n",
        "                    for feature, weight in explanation.as_list():\n",
        "                        if feature.startswith('sem_'):\n",
        "                            semantic_features.append((feature, weight))\n",
        "                        elif any(phrase in feature for phrase in ['engaged', 'debt', 'loans', 'wins', 'losses', 'university', 'professional', 'homeowner']):\n",
        "                            phrase_features.append((feature, weight))\n",
        "                        else:\n",
        "                            classical_features.append((feature, weight))\n",
        "\n",
        "                    if phrase_features:\n",
        "                        print(\"Key Narrative Elements:\")\n",
        "                        for feature, weight in phrase_features:\n",
        "                            direction = \"promotes\" if weight > 0 else \"reduces\"\n",
        "                            print(f\"  {feature} → {direction} subscription ({weight:+.3f})\")\n",
        "\n",
        "                    if semantic_features:\n",
        "                        print(\"Semantic Factors:\")\n",
        "                        for feature, weight in semantic_features[:2]:\n",
        "                            direction = \"promotes\" if weight > 0 else \"reduces\"\n",
        "                            print(f\"  {feature} → {direction} subscription ({weight:+.3f})\")\n",
        "\n",
        "                    if classical_features:\n",
        "                        print(\"Traditional Features:\")\n",
        "                        for feature, weight in classical_features[:2]:\n",
        "                            direction = \"promotes\" if weight > 0 else \"reduces\"\n",
        "                            print(f\"  {feature} → {direction} subscription ({weight:+.3f})\")\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"\\nLIME not available. Install with: pip install lime\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nLIME analysis failed: {e}\")\n",
        "\n",
        "def load_bank_data():\n",
        "    print(\"Loading Bank Marketing dataset...\")\n",
        "\n",
        "    data = pd.read_csv('/content/bank-marketing-dataset.csv', sep=';')\n",
        "    print(\"Loaded from uploaded file\")\n",
        "\n",
        "    key_features = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
        "                   'contact', 'month', 'duration', 'campaign', 'previous', 'poutcome', 'y']\n",
        "\n",
        "    data = data[key_features]\n",
        "\n",
        "    if len(data) > 1500:\n",
        "        print(f\"Sampling 1500 from {len(data)} records for comprehensive LLM comparison\")\n",
        "        data = data.sample(n=1500, random_state=42)\n",
        "\n",
        "    print(f\"Dataset: {len(data)} records\")\n",
        "    print(f\"Subscription rate: {(data['y'] == 'yes').mean():.1%}\")\n",
        "\n",
        "    X = data.drop('y', axis=1)\n",
        "    y = (data['y'] == 'yes').astype(int)\n",
        "\n",
        "    return train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "def calculate_all_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_true, y_pred, zero_division=0)\n",
        "    }\n",
        "\n",
        "def run_fixed_semtab_vs_off_shelf():\n",
        "    print(\"=\"*80)\n",
        "    print(\"FIXED SEMTAB vs OFF-THE-SHELF LLMs COMPREHENSIVE COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = load_bank_data()\n",
        "    print(f\"Split: {len(X_train)} train, {len(X_test)} test\")\n",
        "\n",
        "    framework = FixedSemTabVsOffShelfLLMs()\n",
        "\n",
        "    _, test_narratives = framework.generate_optimized_semtab_features(X_test)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"OFF-THE-SHELF LLM PERFORMANCE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    llm_results = {}\n",
        "\n",
        "    for llm_name in framework.off_shelf_llms.keys():\n",
        "        print(f\"\\nTesting {llm_name}...\")\n",
        "\n",
        "        llm_predictions = framework.predict_with_off_shelf_llm(test_narratives, llm_name)\n",
        "        llm_metrics = calculate_all_metrics(y_test, llm_predictions)\n",
        "\n",
        "        llm_results[llm_name] = {\n",
        "            **llm_metrics,\n",
        "            'predictions': llm_predictions\n",
        "        }\n",
        "\n",
        "        print(f\"{llm_name} - Acc: {llm_metrics['accuracy']:.4f}, Prec: {llm_metrics['precision']:.4f}, Rec: {llm_metrics['recall']:.4f}, F1: {llm_metrics['f1']:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FIXED SEMTAB HYBRID PERFORMANCE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"Training optimized SemTab hybrid model...\")\n",
        "\n",
        "    X_train_classical = framework.prepare_classical_features(X_train, is_training=True)\n",
        "    X_test_classical = framework.prepare_classical_features(X_test, is_training=False)\n",
        "\n",
        "    semantic_train, _ = framework.generate_optimized_semtab_features(X_train)\n",
        "    semantic_test, _ = framework.generate_optimized_semtab_features(X_test)\n",
        "\n",
        "    X_train_hybrid = pd.concat([X_train_classical.reset_index(drop=True),\n",
        "                               semantic_train.reset_index(drop=True)], axis=1)\n",
        "    X_test_hybrid = pd.concat([X_test_classical.reset_index(drop=True),\n",
        "                              semantic_test.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    semtab_model = LogisticRegression(C=0.01, class_weight='balanced',\n",
        "                                     random_state=42, max_iter=2000, solver='liblinear')\n",
        "    semtab_model.fit(X_train_hybrid, y_train)\n",
        "    semtab_predictions = semtab_model.predict(X_test_hybrid)\n",
        "\n",
        "    semtab_metrics = calculate_all_metrics(y_test, semtab_predictions)\n",
        "\n",
        "    print(f\"Fixed SemTab - Acc: {semtab_metrics['accuracy']:.4f}, Prec: {semtab_metrics['precision']:.4f}, Rec: {semtab_metrics['recall']:.4f}, F1: {semtab_metrics['f1']:.4f}\")\n",
        "\n",
        "    framework.explain_semtab_with_lime(semtab_model, X_test_hybrid, X_test_hybrid.columns.tolist(),\n",
        "                                      test_narratives, y_test, semtab_predictions)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(\"COMPREHENSIVE COMPARISON TABLE\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    print(f\"{'Model':<15} {'Accuracy':<10} {'Precision':<11} {'Recall':<9} {'F1-Score':<10} {'vs SemTab F1':<12}\")\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "    sorted_llms = sorted(llm_results.items(), key=lambda x: x[1]['f1'], reverse=True)\n",
        "\n",
        "    for llm_name, results in sorted_llms:\n",
        "        vs_semtab = ((semtab_metrics['f1'] - results['f1']) / results['f1'] * 100) if results['f1'] > 0 else 0\n",
        "        print(f\"{llm_name:<15} {results['accuracy']:<10.4f} {results['precision']:<11.4f} {results['recall']:<9.4f} {results['f1']:<10.4f} {vs_semtab:+.1f}%\")\n",
        "\n",
        "    print(\"-\" * 90)\n",
        "    print(f\"{'SemTab Hybrid':<15} {semtab_metrics['accuracy']:<10.4f} {semtab_metrics['precision']:<11.4f} {semtab_metrics['recall']:<9.4f} {semtab_metrics['f1']:<10.4f} {'Baseline':<12}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"KEY FINDINGS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    best_llm = max(llm_results.items(), key=lambda x: x[1]['f1'])\n",
        "    best_llm_name, best_llm_results = best_llm\n",
        "\n",
        "    semtab_vs_best = ((semtab_metrics['f1'] - best_llm_results['f1']) / best_llm_results['f1'] * 100) if best_llm_results['f1'] > 0 else 0\n",
        "\n",
        "    print(f\"Best Off-the-Shelf LLM: {best_llm_name} (F1: {best_llm_results['f1']:.4f})\")\n",
        "    print(f\"Fixed SemTab Hybrid: F1: {semtab_metrics['f1']:.4f}\")\n",
        "    print(f\"SemTab vs Best LLM: {semtab_vs_best:+.1f}% F1 improvement\")\n",
        "\n",
        "    if semtab_metrics['f1'] > best_llm_results['f1']:\n",
        "        print(f\"SUCCESS: Fixed SemTab outperforms all off-the-shelf LLMs!\")\n",
        "    else:\n",
        "        print(f\"CHALLENGE: {best_llm_name} still outperforms SemTab\")\n",
        "\n",
        "    wins = sum(1 for results in llm_results.values() if semtab_metrics['f1'] > results['f1'])\n",
        "    print(f\"SemTab wins against {wins}/{len(llm_results)} off-the-shelf LLMs\")\n",
        "\n",
        "    print(f\"\\nRecall Analysis:\")\n",
        "    print(f\"SemTab Recall: {semtab_metrics['recall']:.4f} (catching {semtab_metrics['recall']*100:.1f}% of subscribers)\")\n",
        "    print(f\"Best LLM Recall: {best_llm_results['recall']:.4f} (catching {best_llm_results['recall']*100:.1f}% of subscribers)\")\n",
        "\n",
        "    return {\n",
        "        'semtab': semtab_metrics,\n",
        "        'llms': llm_results,\n",
        "        'best_llm': best_llm_name,\n",
        "        'semtab_vs_best': semtab_vs_best\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = run_fixed_semtab_vs_off_shelf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1a31d496d56549b4bd280cc84b859528",
            "17f8700bd58042f281ecedc2d659679a",
            "6c00769c5f7443199462453060f87c74",
            "889f802c0caa4e15a3ab9543606ed865",
            "0f8701b9bdca4ad9a58171ec7d29c35e",
            "87d8628bcbf247fb9d4ede210834669b",
            "02ce021a5b7a4100bd3a017d497f37da",
            "3ed10ee3455b4f52952139185c1f1a1c",
            "558e0602834e4f01891bb916b32b590c",
            "03b27e94d753495c9a82d96698bced11",
            "1f93be00f7f94a3da9b60e296a93613f",
            "c76a97423b6f4041a45cf6df61b416c0",
            "eb926741b94d47ac891510994fa8c71a",
            "5622041080c8460ebc87eb4e87fa4c1a",
            "b19ad18a41f74b9a90a041f5468fb23d",
            "5d0b4500d01443af9eb1e20d49e55eb8",
            "0ab8f87e79e74bfab085865fa716ce9f",
            "fbd449606d53462bba6bbee4885925ac",
            "2c8333a16bc44d48957a31e34bfee640",
            "252ca6102cb247df94f92d66772d4210",
            "45d848f07d97469aadeae97bcd83252b",
            "c09006aea3374afdb4ad04e6a502d52f",
            "92d6ecde684d42fcbee3713c4c174fc5",
            "dd3e14bea8554e8b80a9bc34cb3a9b56",
            "0c76a52713504a1ba6907572f3f3dd18",
            "98952d4d9669422fbb8acefc60d21a88",
            "17cd6de8f64147edb9b4c048edf026c2",
            "55891c2260cc4057acc704843755c9eb",
            "1560546497ca49ff9d4083bcfe579153",
            "998c71ca0bd44e0282209713902b936f",
            "2ebbd9157e3441f897fd2cd59506837e",
            "a62155068d73424eb6a65f2299a85b9f",
            "4be76db68b4645aca6d01744d1138ed3"
          ]
        },
        "id": "3IBR7dq37zst",
        "outputId": "2ba38945-557a-47b4-acc7-da844cc4bf96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FIXED SEMTAB vs OFF-THE-SHELF LLMs COMPREHENSIVE COMPARISON\n",
            "================================================================================\n",
            "Loading Bank Marketing dataset...\n",
            "Loaded from uploaded file\n",
            "Sampling 1500 from 41188 records for comprehensive LLM comparison\n",
            "Dataset: 1500 records\n",
            "Subscription rate: 11.5%\n",
            "Split: 1050 train, 450 test\n",
            "Loading SemTab components...\n",
            "Loading DistilGPT2 for SemTab...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilGPT2 loaded for SemTab!\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBERT loaded successfully!\n",
            "Loading DistilGPT2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilGPT2 loaded successfully!\n",
            "Loading OPT-125M...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPT-125M loaded successfully!\n",
            "Loading GPT2-Small...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2-Small loaded successfully!\n",
            "Fixed SemTab vs Off-the-Shelf LLMs Framework ready!\n",
            "Creating optimized SemTab features for 450 samples...\n",
            "SemTab Progress: 0/450\n",
            "SemTab Progress: 300/450\n",
            "Converting to embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a31d496d56549b4bd280cc84b859528"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "OFF-THE-SHELF LLM PERFORMANCE\n",
            "================================================================================\n",
            "\n",
            "Testing DistilBERT...\n",
            "Running DistilBERT predictions...\n",
            "DistilBERT Progress: 0/450\n",
            "DistilBERT Progress: 100/450\n",
            "DistilBERT Progress: 200/450\n",
            "DistilBERT Progress: 300/450\n",
            "DistilBERT Progress: 400/450\n",
            "DistilBERT - Acc: 0.7956, Prec: 0.0652, Rec: 0.0577, F1: 0.0612\n",
            "\n",
            "Testing DistilGPT2...\n",
            "Running DistilGPT2 predictions...\n",
            "DistilGPT2 Progress: 0/450\n",
            "DistilGPT2 Progress: 100/450\n",
            "DistilGPT2 Progress: 200/450\n",
            "DistilGPT2 Progress: 300/450\n",
            "DistilGPT2 Progress: 400/450\n",
            "DistilGPT2 - Acc: 0.6022, Prec: 0.1809, Rec: 0.6923, F1: 0.2869\n",
            "\n",
            "Testing OPT-125M...\n",
            "Running OPT-125M predictions...\n",
            "OPT-125M Progress: 0/450\n",
            "OPT-125M Progress: 100/450\n",
            "OPT-125M Progress: 200/450\n",
            "OPT-125M Progress: 300/450\n",
            "OPT-125M Progress: 400/450\n",
            "OPT-125M - Acc: 0.4733, Prec: 0.1401, Rec: 0.6923, F1: 0.2330\n",
            "\n",
            "Testing GPT2-Small...\n",
            "Running GPT2-Small predictions...\n",
            "GPT2-Small Progress: 0/450\n",
            "GPT2-Small Progress: 100/450\n",
            "GPT2-Small Progress: 200/450\n",
            "GPT2-Small Progress: 300/450\n",
            "GPT2-Small Progress: 400/450\n",
            "GPT2-Small - Acc: 0.5667, Prec: 0.1407, Rec: 0.5385, F1: 0.2231\n",
            "\n",
            "================================================================================\n",
            "FIXED SEMTAB HYBRID PERFORMANCE\n",
            "================================================================================\n",
            "Training optimized SemTab hybrid model...\n",
            "Creating optimized SemTab features for 1050 samples...\n",
            "SemTab Progress: 0/1050\n",
            "SemTab Progress: 300/1050\n",
            "SemTab Progress: 600/1050\n",
            "SemTab Progress: 900/1050\n",
            "Converting to embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c76a97423b6f4041a45cf6df61b416c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating optimized SemTab features for 450 samples...\n",
            "SemTab Progress: 0/450\n",
            "SemTab Progress: 300/450\n",
            "Converting to embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92d6ecde684d42fcbee3713c4c174fc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed SemTab - Acc: 0.8044, Prec: 0.3235, Rec: 0.6346, F1: 0.4286\n",
            "\n",
            "LIME Interpretability Analysis\n",
            "==================================================\n",
            "\n",
            "Sample 1 LIME Explanation:\n",
            "Narrative: middle-aged single housemaid with basic.4y, homeowner with mortgage, engaged 219s call via cellular. 1-800-989-8255\n",
            "Actual: Subscribe\n",
            "Predicted: Not Subscribe\n",
            "Traditional Features:\n",
            "  previous <= 0.00 → reduces subscription (-0.105)\n",
            "  campaign <= 1.00 → promotes subscription (+0.075)\n",
            "\n",
            "Sample 2 LIME Explanation:\n",
            "Narrative: middle-aged divorced retired with high.school, homeowner with mortgage, engaged 247s call via cellular, 1 prior losses. no, no, no, no,\n",
            "Actual: Not Subscribe\n",
            "Predicted: Not Subscribe\n",
            "Key Narrative Elements:\n",
            "  prior_wins <= 0.00 → reduces subscription (-0.108)\n",
            "Traditional Features:\n",
            "  previous > 0.00 → promotes subscription (+0.097)\n",
            "  186.00 < duration <= 328.50 → reduces subscription (-0.056)\n",
            "\n",
            "Sample 3 LIME Explanation:\n",
            "Narrative: middle-aged married unemployed with professional.course, debt-free, brief 171s call via telephone\n",
            "Actual: Not Subscribe\n",
            "Predicted: Not Subscribe\n",
            "Traditional Features:\n",
            "  108.00 < duration <= 186.00 → reduces subscription (-0.169)\n",
            "  previous <= 0.00 → reduces subscription (-0.122)\n",
            "\n",
            "==========================================================================================\n",
            "COMPREHENSIVE COMPARISON TABLE\n",
            "==========================================================================================\n",
            "Model           Accuracy   Precision   Recall    F1-Score   vs SemTab F1\n",
            "------------------------------------------------------------------------------------------\n",
            "DistilGPT2      0.6022     0.1809      0.6923    0.2869     +49.4%\n",
            "OPT-125M        0.4733     0.1401      0.6923    0.2330     +83.9%\n",
            "GPT2-Small      0.5667     0.1407      0.5385    0.2231     +92.1%\n",
            "DistilBERT      0.7956     0.0652      0.0577    0.0612     +600.0%\n",
            "------------------------------------------------------------------------------------------\n",
            "SemTab Hybrid   0.8044     0.3235      0.6346    0.4286     Baseline    \n",
            "\n",
            "================================================================================\n",
            "KEY FINDINGS\n",
            "================================================================================\n",
            "Best Off-the-Shelf LLM: DistilGPT2 (F1: 0.2869)\n",
            "Fixed SemTab Hybrid: F1: 0.4286\n",
            "SemTab vs Best LLM: +49.4% F1 improvement\n",
            "SUCCESS: Fixed SemTab outperforms all off-the-shelf LLMs!\n",
            "SemTab wins against 4/4 off-the-shelf LLMs\n",
            "\n",
            "Recall Analysis:\n",
            "SemTab Recall: 0.6346 (catching 63.5% of subscribers)\n",
            "Best LLM Recall: 0.6923 (catching 69.2% of subscribers)\n"
          ]
        }
      ]
    }
  ]
}