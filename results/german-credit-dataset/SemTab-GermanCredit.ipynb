{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1Fzkwkv7qfWE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fzkwkv7qfWE",
        "outputId": "a72b163e-1466-452c-882b-85f7118f2a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m266.2/275.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=af11e4caa80c96921e829a5e1913dad639b57e51b8b03ae0b6de42174eec3ba5\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "XtXsmN5Ycza8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a20bdd7511ce4fe2a14955395c1a2f2b",
            "eae1955a6d574943abc39262d965f29e",
            "1638b6723e084ac4aaf2813213233c3b",
            "91cfc3fa32b54fdaa5fcc645fb9e6323",
            "f8b24bacdbbc4b7ca63e5c42c4581449",
            "b7359d6374a0441593ee156d64a5230d",
            "948fb3438e124f44b164e7e1a30f8b18",
            "ef650e7dc5bc4fefaa24027f0ac1f704",
            "9809ae71d1d343e69e0779eecf23b66b",
            "90069a3aa0804ab683304f51245fb29c",
            "1210bc28cd9b4822bfb1a8e12e7ab3d7",
            "1c1e906326604fcdbbd2ad53f5277b2e",
            "977830309b8a446fb0ff5306ccae0f26",
            "c2e43ba7c7dd4e09b68d81102beef8cb",
            "85676e83ac97471ebbf6ad91ea9fcfe1",
            "ce7c1af8355c483691d394f51a8aeec3",
            "4136717dd2a0443e8249f0d51cc422a6",
            "86ea3f1eec4f4555a1cb68151f826878",
            "4999b0231db44570a40532fce0699e40",
            "1493aba0587a4613bfb9ad51dddb272d",
            "56c0943b49e84a808f62174a78ef7842",
            "e3f7152b32f24f40813b11e6885759c3",
            "057cd35c0783488098f6b9a5ecd0ccc8",
            "c2a3fec42a3c4a04a0193306a4f60ea3",
            "b242b95302474ed0aa7a493dc7987327",
            "6f01dce836974b6f92221e157fcce7b2",
            "a1299734d0e649cd9b6f91fa574dd612",
            "ae0f983d461b49878f3ead5b8270a7a3",
            "1f50127a25a24e43856470662653313f",
            "aa94e6b2508b4c668005de5c3359bcf3",
            "0a402bc2162c4d7a9f5649a4526b3b7a",
            "6468fd8824ac4db8844eff8dcdbe676c",
            "011ab2bd2ab246b3b8fedf6afec8ef90"
          ]
        },
        "id": "XtXsmN5Ycza8",
        "outputId": "66eb4828-fbab-4e9b-dda4-01d6e5f34ae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.11/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "================================================================================\n",
            "FIXED SEMTAB vs OFF-THE-SHELF LLMs: GERMAN CREDIT DATASET\n",
            "================================================================================\n",
            "Loading German Credit dataset...\n",
            "Sampling 800 from 1000 records for LLM comparison\n",
            "Dataset: 800 records\n",
            "Low risk rate: 70.0%\n",
            "Split: 560 train, 240 test\n",
            "Loading SemTab components...\n",
            "Loading DistilGPT2 for SemTab...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilGPT2 loaded for SemTab!\n",
            "Loading DistilBERT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBERT loaded successfully!\n",
            "Loading DistilGPT2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilGPT2 loaded successfully!\n",
            "Loading OPT-125M...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPT-125M loaded successfully!\n",
            "Loading GPT2-Small...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT2-Small loaded successfully!\n",
            "Fixed SemTab German Credit Framework ready!\n",
            "Creating optimized credit features for 240 samples...\n",
            "Credit SemTab Progress: 0/240\n",
            "Credit SemTab Progress: 200/240\n",
            "Converting to embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a20bdd7511ce4fe2a14955395c1a2f2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "OFF-THE-SHELF LLM PERFORMANCE ON GERMAN CREDIT\n",
            "================================================================================\n",
            "\n",
            "Testing DistilBERT...\n",
            "Running DistilBERT predictions...\n",
            "DistilBERT Progress: 0/240\n",
            "DistilBERT Progress: 50/240\n",
            "DistilBERT Progress: 100/240\n",
            "DistilBERT Progress: 150/240\n",
            "DistilBERT Progress: 200/240\n",
            "DistilBERT - Acc: 0.4500, Prec: 0.7432, Rec: 0.3274, F1: 0.4545\n",
            "\n",
            "Testing DistilGPT2...\n",
            "Running DistilGPT2 predictions...\n",
            "DistilGPT2 Progress: 0/240\n",
            "DistilGPT2 Progress: 50/240\n",
            "DistilGPT2 Progress: 100/240\n",
            "DistilGPT2 Progress: 150/240\n",
            "DistilGPT2 Progress: 200/240\n",
            "DistilGPT2 - Acc: 0.4667, Prec: 0.7174, Rec: 0.3929, F1: 0.5077\n",
            "\n",
            "Testing OPT-125M...\n",
            "Running OPT-125M predictions...\n",
            "OPT-125M Progress: 0/240\n",
            "OPT-125M Progress: 50/240\n",
            "OPT-125M Progress: 100/240\n",
            "OPT-125M Progress: 150/240\n",
            "OPT-125M Progress: 200/240\n",
            "OPT-125M - Acc: 0.4917, Prec: 0.7556, Rec: 0.4048, F1: 0.5271\n",
            "\n",
            "Testing GPT2-Small...\n",
            "Running GPT2-Small predictions...\n",
            "GPT2-Small Progress: 0/240\n",
            "GPT2-Small Progress: 50/240\n",
            "GPT2-Small Progress: 100/240\n",
            "GPT2-Small Progress: 150/240\n",
            "GPT2-Small Progress: 200/240\n",
            "GPT2-Small - Acc: 0.4458, Prec: 0.7273, Rec: 0.3333, F1: 0.4571\n",
            "\n",
            "================================================================================\n",
            "FIXED SEMTAB HYBRID PERFORMANCE ON GERMAN CREDIT\n",
            "================================================================================\n",
            "Training optimized German Credit SemTab model...\n",
            "Creating optimized credit features for 560 samples...\n",
            "Credit SemTab Progress: 0/560\n",
            "Credit SemTab Progress: 200/560\n",
            "Credit SemTab Progress: 400/560\n",
            "Converting to embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c1e906326604fcdbbd2ad53f5277b2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating optimized credit features for 240 samples...\n",
            "Credit SemTab Progress: 0/240\n",
            "Credit SemTab Progress: 200/240\n",
            "Converting to embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "057cd35c0783488098f6b9a5ecd0ccc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed German Credit SemTab - Acc: 0.6958, Prec: 0.8065, Rec: 0.7440, F1: 0.7740\n",
            "\n",
            "LIME Credit Risk Interpretability Analysis\n",
            "=======================================================\n",
            "\n",
            "Sample 1 LIME Explanation:\n",
            "Credit Narrative: middle-aged female seeking $3,612 loan for furniture over 18 months, critical credit issues, very stable employment, minimal savings, has insurance/savings\n",
            "Actual: Low Risk\n",
            "Predicted: Low Risk\n",
            "Key Credit Risk Elements:\n",
            "  savings <= 0.00 → increases credit risk (-0.083)\n",
            "  2.00 < credit_history <= 4.00 → reduces credit risk (+0.062)\n",
            "  2.00 < employment_duration <= 4.00 → reduces credit risk (+0.031)\n",
            "Traditional Credit Features:\n",
            "  0.00 < status <= 1.00 → increases credit risk (-0.069)\n",
            "  12.00 < duration <= 18.00 → reduces credit risk (+0.047)\n",
            "\n",
            "Sample 2 LIME Explanation:\n",
            "Credit Narrative: middle-aged single male seeking $5,742 loan for business over 36 months, satisfactory credit, long-term employment, modest savings, owns vehicle/property\n",
            "Actual: Low Risk\n",
            "Predicted: High Risk\n",
            "Key Credit Risk Elements:\n",
            "  credit_history <= 2.00 → increases credit risk (-0.072)\n",
            "  2.00 < employment_duration <= 4.00 → reduces credit risk (+0.028)\n",
            "Traditional Credit Features:\n",
            "  1.00 < status <= 3.00 → reduces credit risk (+0.182)\n",
            "  duration > 27.00 → increases credit risk (-0.173)\n",
            "\n",
            "Sample 3 LIME Explanation:\n",
            "Credit Narrative: young single male seeking $5,152 loan for electronics over 24 months, satisfactory credit, long-term employment, minimal savings, owns vehicle/property\n",
            "Actual: Low Risk\n",
            "Predicted: High Risk\n",
            "Key Credit Risk Elements:\n",
            "  savings <= 0.00 → increases credit risk (-0.084)\n",
            "  credit_history <= 2.00 → increases credit risk (-0.071)\n",
            "  2.00 < employment_duration <= 4.00 → reduces credit risk (+0.032)\n",
            "Traditional Credit Features:\n",
            "  1.00 < status <= 3.00 → reduces credit risk (+0.183)\n",
            "  amount > 3817.00 → increases credit risk (-0.040)\n",
            "\n",
            "===============================================================================================\n",
            "GERMAN CREDIT COMPREHENSIVE COMPARISON TABLE\n",
            "===============================================================================================\n",
            "Model           Accuracy   Precision   Recall    F1-Score   vs SemTab F1\n",
            "-----------------------------------------------------------------------------------------------\n",
            "OPT-125M        0.4917     0.7556      0.4048    0.5271     +46.8%\n",
            "DistilGPT2      0.4667     0.7174      0.3929    0.5077     +52.5%\n",
            "GPT2-Small      0.4458     0.7273      0.3333    0.4571     +69.3%\n",
            "DistilBERT      0.4500     0.7432      0.3274    0.4545     +70.3%\n",
            "-----------------------------------------------------------------------------------------------\n",
            "SemTab Hybrid   0.6958     0.8065      0.7440    0.7740     Baseline    \n",
            "\n",
            "================================================================================\n",
            "GERMAN CREDIT KEY FINDINGS\n",
            "================================================================================\n",
            "Best Off-the-Shelf LLM: OPT-125M (F1: 0.5271)\n",
            "German Credit SemTab: F1: 0.7740\n",
            "SemTab vs Best LLM: +46.8% F1 improvement\n",
            "SUCCESS: SemTab outperforms all off-the-shelf LLMs on German Credit!\n",
            "SemTab wins against 4/4 off-the-shelf LLMs\n",
            "\n",
            "Credit Risk Analysis:\n",
            "SemTab identifies 74.4% of low-risk applicants\n",
            "SemTab precision: 80.6% of predicted low-risk are actually low-risk\n",
            "\n",
            "Sample Credit Risk Narratives:\n",
            "\n",
            "Sample 1: middle-aged female seeking $3,612 loan for furniture over 18 months, critical credit issues, very stable employment, min...\n",
            "Actual: Low Risk | SemTab: Low Risk\n",
            "\n",
            "Sample 2: middle-aged single male seeking $5,742 loan for business over 36 months, satisfactory credit, long-term employment, mode...\n",
            "Actual: Low Risk | SemTab: High Risk\n"
          ]
        }
      ],
      "source": [
        "#Final Code\n",
        "\n",
        "!pip install lime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FixedSemTabGermanCredit:\n",
        "    def __init__(self):\n",
        "        self.label_encoders = {}\n",
        "        print(\"Loading SemTab components...\")\n",
        "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "        try:\n",
        "            from transformers import pipeline\n",
        "            print(\"Loading DistilGPT2 for SemTab...\")\n",
        "            self.llm = pipeline('text-generation',\n",
        "                               model='distilgpt2',\n",
        "                               max_length=80,\n",
        "                               do_sample=True,\n",
        "                               temperature=0.5,\n",
        "                               pad_token_id=50256)\n",
        "            print(\"DistilGPT2 loaded for SemTab!\")\n",
        "            self.use_llm = True\n",
        "        except Exception as e:\n",
        "            print(f\"LLM loading failed: {e}\")\n",
        "            self.use_llm = False\n",
        "\n",
        "        self.off_shelf_llms = {}\n",
        "        self.load_off_shelf_llms()\n",
        "\n",
        "        print(\"Fixed SemTab German Credit Framework ready!\")\n",
        "\n",
        "    def load_off_shelf_llms(self):\n",
        "        from transformers import pipeline\n",
        "\n",
        "        llm_configs = {\n",
        "            'DistilBERT': {\n",
        "                'model': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
        "                'task': 'text-classification'\n",
        "            },\n",
        "            'DistilGPT2': {\n",
        "                'model': 'distilgpt2',\n",
        "                'task': 'text-generation'\n",
        "            },\n",
        "            'OPT-125M': {\n",
        "                'model': 'facebook/opt-125m',\n",
        "                'task': 'text-generation'\n",
        "            },\n",
        "            'GPT2-Small': {\n",
        "                'model': 'gpt2',\n",
        "                'task': 'text-generation'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for name, config in llm_configs.items():\n",
        "            try:\n",
        "                print(f\"Loading {name}...\")\n",
        "                if config['task'] == 'text-classification':\n",
        "                    llm = pipeline(config['task'], model=config['model'], return_all_scores=True)\n",
        "                else:\n",
        "                    llm = pipeline(config['task'], model=config['model'],\n",
        "                                  max_length=70, do_sample=True, temperature=0.6,\n",
        "                                  pad_token_id=50256)\n",
        "                self.off_shelf_llms[name] = {'pipeline': llm, 'task': config['task']}\n",
        "                print(f\"{name} loaded successfully!\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load {name}: {e}\")\n",
        "                self.off_shelf_llms[name] = {'pipeline': None, 'task': 'failed'}\n",
        "\n",
        "    def create_credit_narrative(self, row):\n",
        "        age_desc = \"young\" if row['age'] < 30 else \"senior\" if row['age'] > 50 else \"middle-aged\"\n",
        "        gender_desc = self._get_gender_desc(row)\n",
        "\n",
        "        narrative = f\"{age_desc} {gender_desc} seeking ${row['amount']:,} loan\"\n",
        "        narrative += f\" for {self._get_purpose_desc(row['purpose'])}\"\n",
        "        narrative += f\" over {row['duration']} months\"\n",
        "\n",
        "        credit_desc = self._get_credit_desc(row['credit_history'])\n",
        "        narrative += f\", {credit_desc}\"\n",
        "\n",
        "        employment_desc = self._get_employment_desc(row['employment_duration'])\n",
        "        narrative += f\", {employment_desc}\"\n",
        "\n",
        "        savings_desc = self._get_savings_desc(row['savings'])\n",
        "        narrative += f\", {savings_desc}\"\n",
        "\n",
        "        if 'property' in row:\n",
        "            property_desc = self._get_property_desc(row['property'])\n",
        "            if property_desc:\n",
        "                narrative += f\", {property_desc}\"\n",
        "\n",
        "        return narrative\n",
        "\n",
        "    def _get_gender_desc(self, row):\n",
        "        if 'statussex' in row:\n",
        "            gender_map = {\n",
        "                'A91': \"divorced male\",\n",
        "                'A92': \"female\",\n",
        "                'A93': \"single male\",\n",
        "                'A94': \"married male\",\n",
        "                'A95': \"single female\"\n",
        "            }\n",
        "            return gender_map.get(row['statussex'], \"individual\")\n",
        "        return \"individual\"\n",
        "\n",
        "    def _get_purpose_desc(self, purpose):\n",
        "        purpose_map = {\n",
        "            'A40': 'new car purchase',\n",
        "            'A41': 'used car purchase',\n",
        "            'A42': 'furniture',\n",
        "            'A43': 'electronics',\n",
        "            'A44': 'appliances',\n",
        "            'A45': 'repairs',\n",
        "            'A46': 'education',\n",
        "            'A47': 'vacation',\n",
        "            'A48': 'retraining',\n",
        "            'A49': 'business',\n",
        "            'A410': 'other needs'\n",
        "        }\n",
        "        return purpose_map.get(purpose, 'general purpose')\n",
        "\n",
        "    def _get_credit_desc(self, credit_history):\n",
        "        credit_map = {\n",
        "            'A30': 'excellent credit record',\n",
        "            'A31': 'good credit history',\n",
        "            'A32': 'satisfactory credit',\n",
        "            'A33': 'payment delays',\n",
        "            'A34': 'critical credit issues'\n",
        "        }\n",
        "        return credit_map.get(credit_history, 'standard credit')\n",
        "\n",
        "    def _get_employment_desc(self, employment_duration):\n",
        "        employment_map = {\n",
        "            'A71': 'unemployed',\n",
        "            'A72': 'short employment history',\n",
        "            'A73': 'stable employment',\n",
        "            'A74': 'long-term employment',\n",
        "            'A75': 'very stable employment'\n",
        "        }\n",
        "        return employment_map.get(employment_duration, 'standard employment')\n",
        "\n",
        "    def _get_savings_desc(self, savings):\n",
        "        savings_map = {\n",
        "            'A61': 'minimal savings',\n",
        "            'A62': 'modest savings',\n",
        "            'A63': 'moderate savings',\n",
        "            'A64': 'substantial savings',\n",
        "            'A65': 'extensive savings'\n",
        "        }\n",
        "        return savings_map.get(savings, 'undisclosed savings')\n",
        "\n",
        "    def _get_property_desc(self, property_code):\n",
        "        property_map = {\n",
        "            'A121': 'owns real estate',\n",
        "            'A122': 'has insurance/savings',\n",
        "            'A123': 'owns vehicle/property',\n",
        "            'A124': 'no property'\n",
        "        }\n",
        "        return property_map.get(property_code, '')\n",
        "\n",
        "    def enhance_credit_narrative(self, narrative):\n",
        "        if not self.use_llm:\n",
        "            return narrative\n",
        "\n",
        "        try:\n",
        "            prompt = f\"Credit applicant: {narrative}. Risk assessment:\"\n",
        "            result = self.llm(prompt, max_new_tokens=8, num_return_sequences=1)\n",
        "            llm_text = result[0]['generated_text']\n",
        "            enhancement = llm_text.replace(prompt, \"\").strip()\n",
        "\n",
        "            if len(enhancement) > 3 and len(enhancement) < 25:\n",
        "                clean_enhancement = enhancement.split('.')[0].strip()\n",
        "                if len(clean_enhancement) > 3:\n",
        "                    return f\"{narrative}. {clean_enhancement}\"\n",
        "\n",
        "            return narrative\n",
        "        except:\n",
        "            return narrative\n",
        "\n",
        "    def predict_with_off_shelf_llm(self, narratives, llm_name):\n",
        "        if llm_name not in self.off_shelf_llms or self.off_shelf_llms[llm_name]['pipeline'] is None:\n",
        "            return np.random.choice([0, 1], len(narratives), p=[0.7, 0.3])\n",
        "\n",
        "        llm_info = self.off_shelf_llms[llm_name]\n",
        "        llm = llm_info['pipeline']\n",
        "        task = llm_info['task']\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        print(f\"Running {llm_name} predictions...\")\n",
        "        for i, narrative in enumerate(narratives):\n",
        "            if i % 50 == 0:\n",
        "                print(f\"{llm_name} Progress: {i}/{len(narratives)}\")\n",
        "\n",
        "            try:\n",
        "                if task == 'text-classification':\n",
        "                    prompt = f\"Is this a low credit risk applicant: {narrative}\"\n",
        "                    result = llm(prompt)\n",
        "                    positive_score = result[0]['score'] if result[0]['label'] == 'POSITIVE' else result[1]['score']\n",
        "                    prediction = 1 if positive_score > 0.5 else 0\n",
        "\n",
        "                elif task == 'text-generation':\n",
        "                    prompt = f\"Credit risk: {narrative}. Low risk? Yes/No:\"\n",
        "                    result = llm(prompt, max_new_tokens=3, num_return_sequences=1)\n",
        "                    output = result[0]['generated_text'].replace(prompt, \"\").strip().lower()\n",
        "\n",
        "                    if any(pos_word in output for pos_word in ['yes', 'low', 'good', 'safe']):\n",
        "                        prediction = 1\n",
        "                    elif any(neg_word in output for neg_word in ['no', 'high', 'risky', 'bad']):\n",
        "                        prediction = 0\n",
        "                    else:\n",
        "                        positive_signals = sum(1 for word in ['excellent', 'good', 'stable', 'substantial', 'real estate'] if word in narrative.lower())\n",
        "                        negative_signals = sum(1 for word in ['critical', 'delays', 'unemployed', 'minimal'] if word in narrative.lower())\n",
        "                        prediction = 1 if positive_signals > negative_signals else 0\n",
        "\n",
        "                predictions.append(prediction)\n",
        "\n",
        "            except:\n",
        "                prediction = np.random.choice([0, 1], p=[0.7, 0.3])\n",
        "                predictions.append(prediction)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def generate_optimized_credit_features(self, df):\n",
        "        print(f\"Creating optimized credit features for {len(df)} samples...\")\n",
        "\n",
        "        narratives = []\n",
        "        for idx, (_, row) in enumerate(df.iterrows()):\n",
        "            if idx % 200 == 0:\n",
        "                print(f\"Credit SemTab Progress: {idx}/{len(df)}\")\n",
        "\n",
        "            narrative = self.create_credit_narrative(row)\n",
        "\n",
        "            if self.use_llm and np.random.random() < 0.5:\n",
        "                narrative = self.enhance_credit_narrative(narrative)\n",
        "\n",
        "            narratives.append(narrative)\n",
        "\n",
        "        print(\"Converting to embeddings...\")\n",
        "        embeddings = self.embedding_model.encode(narratives, show_progress_bar=True)\n",
        "\n",
        "        from sklearn.decomposition import PCA\n",
        "        pca = PCA(n_components=10)\n",
        "        reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "        semantic_df = pd.DataFrame(reduced_embeddings, columns=[f'sem_{i}' for i in range(10)])\n",
        "\n",
        "        phrase_features = []\n",
        "        for narrative in narratives:\n",
        "            features = {\n",
        "                'excellent_credit': 1 if 'excellent credit' in narrative else 0,\n",
        "                'good_credit': 1 if 'good credit' in narrative else 0,\n",
        "                'critical_issues': 1 if 'critical' in narrative else 0,\n",
        "                'payment_delays': 1 if 'delays' in narrative else 0,\n",
        "                'stable_employment': 1 if 'stable employment' in narrative or 'long-term employment' in narrative else 0,\n",
        "                'substantial_savings': 1 if 'substantial' in narrative or 'extensive' in narrative else 0,\n",
        "                'owns_property': 1 if 'real estate' in narrative or 'owns' in narrative else 0,\n",
        "                'business_purpose': 1 if 'business' in narrative else 0\n",
        "            }\n",
        "            phrase_features.append(features)\n",
        "\n",
        "        phrase_df = pd.DataFrame(phrase_features)\n",
        "        final_features = pd.concat([semantic_df, phrase_df], axis=1)\n",
        "\n",
        "        return final_features, narratives\n",
        "\n",
        "    def prepare_classical_features(self, df, is_training=True):\n",
        "        df_copy = df.copy()\n",
        "\n",
        "        categorical_cols = ['status', 'credit_history', 'purpose', 'savings',\n",
        "                           'employment_duration']\n",
        "        if 'property' in df_copy.columns:\n",
        "            categorical_cols.append('property')\n",
        "        if 'statussex' in df_copy.columns:\n",
        "            categorical_cols.append('statussex')\n",
        "\n",
        "        for col in categorical_cols:\n",
        "            if col in df_copy.columns:\n",
        "                if is_training:\n",
        "                    self.label_encoders[col] = LabelEncoder()\n",
        "                    df_copy[col] = self.label_encoders[col].fit_transform(df_copy[col].astype(str))\n",
        "                else:\n",
        "                    if col in self.label_encoders:\n",
        "                        unknown_mask = ~df_copy[col].astype(str).isin(self.label_encoders[col].classes_)\n",
        "                        if unknown_mask.any():\n",
        "                            df_copy.loc[unknown_mask, col] = self.label_encoders[col].classes_[0]\n",
        "                        df_copy[col] = self.label_encoders[col].transform(df_copy[col].astype(str))\n",
        "\n",
        "        return df_copy\n",
        "\n",
        "    def explain_credit_semtab_with_lime(self, model, X_test, feature_names, narratives, y_test, predictions, sample_indices=[0, 1, 2]):\n",
        "        try:\n",
        "            from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "            print(\"\\nLIME Credit Risk Interpretability Analysis\")\n",
        "            print(\"=\"*55)\n",
        "\n",
        "            explainer = LimeTabularExplainer(\n",
        "                X_test.values,\n",
        "                feature_names=feature_names,\n",
        "                class_names=['High Risk', 'Low Risk'],\n",
        "                mode='classification',\n",
        "                discretize_continuous=True\n",
        "            )\n",
        "\n",
        "            for i, idx in enumerate(sample_indices):\n",
        "                if idx < len(X_test):\n",
        "                    print(f\"\\nSample {i+1} LIME Explanation:\")\n",
        "                    print(f\"Credit Narrative: {narratives[idx]}\")\n",
        "                    print(f\"Actual: {'Low Risk' if y_test.iloc[idx] == 1 else 'High Risk'}\")\n",
        "                    print(f\"Predicted: {'Low Risk' if predictions[idx] == 1 else 'High Risk'}\")\n",
        "\n",
        "                    explanation = explainer.explain_instance(\n",
        "                        X_test.iloc[idx].values,\n",
        "                        model.predict_proba,\n",
        "                        num_features=6\n",
        "                    )\n",
        "\n",
        "                    semantic_features = []\n",
        "                    phrase_features = []\n",
        "                    classical_features = []\n",
        "\n",
        "                    for feature, weight in explanation.as_list():\n",
        "                        if feature.startswith('sem_'):\n",
        "                            semantic_features.append((feature, weight))\n",
        "                        elif any(phrase in feature for phrase in ['credit', 'employment', 'savings', 'property', 'business', 'delays']):\n",
        "                            phrase_features.append((feature, weight))\n",
        "                        else:\n",
        "                            classical_features.append((feature, weight))\n",
        "\n",
        "                    if phrase_features:\n",
        "                        print(\"Key Credit Risk Elements:\")\n",
        "                        for feature, weight in phrase_features:\n",
        "                            direction = \"reduces\" if weight > 0 else \"increases\"\n",
        "                            print(f\"  {feature} → {direction} credit risk ({weight:+.3f})\")\n",
        "\n",
        "                    if semantic_features:\n",
        "                        print(\"Semantic Context Factors:\")\n",
        "                        for feature, weight in semantic_features[:2]:\n",
        "                            direction = \"reduces\" if weight > 0 else \"increases\"\n",
        "                            print(f\"  {feature} → {direction} credit risk ({weight:+.3f})\")\n",
        "\n",
        "                    if classical_features:\n",
        "                        print(\"Traditional Credit Features:\")\n",
        "                        for feature, weight in classical_features[:2]:\n",
        "                            direction = \"reduces\" if weight > 0 else \"increases\"\n",
        "                            print(f\"  {feature} → {direction} credit risk ({weight:+.3f})\")\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"\\nLIME not available. Install with: pip install lime\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nLIME analysis failed: {e}\")\n",
        "\n",
        "def load_german_credit_data():\n",
        "    print(\"Loading German Credit dataset...\")\n",
        "\n",
        "    data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data',\n",
        "                       header=None, sep=' ')\n",
        "    feature_names = ['status', 'duration', 'credit_history', 'purpose', 'amount',\n",
        "                     'savings', 'employment_duration', 'installment_rate', 'statussex',\n",
        "                     'other_debtors', 'residence_since', 'property', 'age', 'other_installment_plans',\n",
        "                     'housing', 'number_credits', 'job', 'people_liable', 'telephone', 'foreign_worker',\n",
        "                     'credit_risk']\n",
        "    data.columns = feature_names\n",
        "\n",
        "    data['credit_risk'] = data['credit_risk'].map({1: 1, 2: 0})\n",
        "\n",
        "    key_features = ['status', 'duration', 'credit_history', 'purpose', 'amount',\n",
        "                   'savings', 'employment_duration', 'statussex', 'property', 'age', 'credit_risk']\n",
        "\n",
        "    data = data[key_features]\n",
        "\n",
        "    if len(data) > 800:\n",
        "        print(f\"Sampling 800 from {len(data)} records for LLM comparison\")\n",
        "        data = data.sample(n=800, random_state=42)\n",
        "\n",
        "    print(f\"Dataset: {len(data)} records\")\n",
        "    print(f\"Low risk rate: {(data['credit_risk'] == 1).mean():.1%}\")\n",
        "\n",
        "    X = data.drop('credit_risk', axis=1)\n",
        "    y = data['credit_risk']\n",
        "\n",
        "    return train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "def calculate_all_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_true, y_pred, zero_division=0)\n",
        "    }\n",
        "\n",
        "def run_fixed_semtab_german_credit():\n",
        "    print(\"=\"*80)\n",
        "    print(\"FIXED SEMTAB vs OFF-THE-SHELF LLMs: GERMAN CREDIT DATASET\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = load_german_credit_data()\n",
        "    print(f\"Split: {len(X_train)} train, {len(X_test)} test\")\n",
        "\n",
        "    framework = FixedSemTabGermanCredit()\n",
        "\n",
        "    _, test_narratives = framework.generate_optimized_credit_features(X_test)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"OFF-THE-SHELF LLM PERFORMANCE ON GERMAN CREDIT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    llm_results = {}\n",
        "\n",
        "    for llm_name in framework.off_shelf_llms.keys():\n",
        "        print(f\"\\nTesting {llm_name}...\")\n",
        "\n",
        "        llm_predictions = framework.predict_with_off_shelf_llm(test_narratives, llm_name)\n",
        "        llm_metrics = calculate_all_metrics(y_test, llm_predictions)\n",
        "\n",
        "        llm_results[llm_name] = {\n",
        "            **llm_metrics,\n",
        "            'predictions': llm_predictions\n",
        "        }\n",
        "\n",
        "        print(f\"{llm_name} - Acc: {llm_metrics['accuracy']:.4f}, Prec: {llm_metrics['precision']:.4f}, Rec: {llm_metrics['recall']:.4f}, F1: {llm_metrics['f1']:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FIXED SEMTAB HYBRID PERFORMANCE ON GERMAN CREDIT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"Training optimized German Credit SemTab model...\")\n",
        "\n",
        "    X_train_classical = framework.prepare_classical_features(X_train, is_training=True)\n",
        "    X_test_classical = framework.prepare_classical_features(X_test, is_training=False)\n",
        "\n",
        "    semantic_train, _ = framework.generate_optimized_credit_features(X_train)\n",
        "    semantic_test, _ = framework.generate_optimized_credit_features(X_test)\n",
        "\n",
        "    X_train_hybrid = pd.concat([X_train_classical.reset_index(drop=True),\n",
        "                               semantic_train.reset_index(drop=True)], axis=1)\n",
        "    X_test_hybrid = pd.concat([X_test_classical.reset_index(drop=True),\n",
        "                              semantic_test.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    semtab_model = LogisticRegression(C=0.01, class_weight='balanced',\n",
        "                                     random_state=42, max_iter=2000, solver='liblinear')\n",
        "    semtab_model.fit(X_train_hybrid, y_train)\n",
        "    semtab_predictions = semtab_model.predict(X_test_hybrid)\n",
        "\n",
        "    semtab_metrics = calculate_all_metrics(y_test, semtab_predictions)\n",
        "\n",
        "    print(f\"Fixed German Credit SemTab - Acc: {semtab_metrics['accuracy']:.4f}, Prec: {semtab_metrics['precision']:.4f}, Rec: {semtab_metrics['recall']:.4f}, F1: {semtab_metrics['f1']:.4f}\")\n",
        "\n",
        "    framework.explain_credit_semtab_with_lime(semtab_model, X_test_hybrid, X_test_hybrid.columns.tolist(),\n",
        "                                             test_narratives, y_test, semtab_predictions)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*95)\n",
        "    print(\"GERMAN CREDIT COMPREHENSIVE COMPARISON TABLE\")\n",
        "    print(\"=\"*95)\n",
        "\n",
        "    print(f\"{'Model':<15} {'Accuracy':<10} {'Precision':<11} {'Recall':<9} {'F1-Score':<10} {'vs SemTab F1':<12}\")\n",
        "    print(\"-\" * 95)\n",
        "\n",
        "    sorted_llms = sorted(llm_results.items(), key=lambda x: x[1]['f1'], reverse=True)\n",
        "\n",
        "    for llm_name, results in sorted_llms:\n",
        "        vs_semtab = ((semtab_metrics['f1'] - results['f1']) / results['f1'] * 100) if results['f1'] > 0 else 0\n",
        "        print(f\"{llm_name:<15} {results['accuracy']:<10.4f} {results['precision']:<11.4f} {results['recall']:<9.4f} {results['f1']:<10.4f} {vs_semtab:+.1f}%\")\n",
        "\n",
        "    print(\"-\" * 95)\n",
        "    print(f\"{'SemTab Hybrid':<15} {semtab_metrics['accuracy']:<10.4f} {semtab_metrics['precision']:<11.4f} {semtab_metrics['recall']:<9.4f} {semtab_metrics['f1']:<10.4f} {'Baseline':<12}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"GERMAN CREDIT KEY FINDINGS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    best_llm = max(llm_results.items(), key=lambda x: x[1]['f1'])\n",
        "    best_llm_name, best_llm_results = best_llm\n",
        "\n",
        "    semtab_vs_best = ((semtab_metrics['f1'] - best_llm_results['f1']) / best_llm_results['f1'] * 100) if best_llm_results['f1'] > 0 else 0\n",
        "\n",
        "    print(f\"Best Off-the-Shelf LLM: {best_llm_name} (F1: {best_llm_results['f1']:.4f})\")\n",
        "    print(f\"German Credit SemTab: F1: {semtab_metrics['f1']:.4f}\")\n",
        "    print(f\"SemTab vs Best LLM: {semtab_vs_best:+.1f}% F1 improvement\")\n",
        "\n",
        "    if semtab_metrics['f1'] > best_llm_results['f1']:\n",
        "        print(f\"SUCCESS: SemTab outperforms all off-the-shelf LLMs on German Credit!\")\n",
        "    else:\n",
        "        print(f\"CHALLENGE: {best_llm_name} still outperforms SemTab on German Credit\")\n",
        "\n",
        "    wins = sum(1 for results in llm_results.values() if semtab_metrics['f1'] > results['f1'])\n",
        "    print(f\"SemTab wins against {wins}/{len(llm_results)} off-the-shelf LLMs\")\n",
        "\n",
        "    print(f\"\\nCredit Risk Analysis:\")\n",
        "    print(f\"SemTab identifies {semtab_metrics['recall']*100:.1f}% of low-risk applicants\")\n",
        "    print(f\"SemTab precision: {semtab_metrics['precision']*100:.1f}% of predicted low-risk are actually low-risk\")\n",
        "\n",
        "    print(\"\\nSample Credit Risk Narratives:\")\n",
        "    for i in range(min(2, len(test_narratives))):\n",
        "        actual = \"Low Risk\" if y_test.iloc[i] == 1 else \"High Risk\"\n",
        "        semtab_pred = \"Low Risk\" if semtab_predictions[i] == 1 else \"High Risk\"\n",
        "\n",
        "        print(f\"\\nSample {i+1}: {test_narratives[i][:120]}...\")\n",
        "        print(f\"Actual: {actual} | SemTab: {semtab_pred}\")\n",
        "\n",
        "    return {\n",
        "        'semtab': semtab_metrics,\n",
        "        'llms': llm_results,\n",
        "        'best_llm': best_llm_name,\n",
        "        'semtab_vs_best': semtab_vs_best\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = run_fixed_semtab_german_credit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76mpRjMydIKJ",
      "metadata": {
        "id": "76mpRjMydIKJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "rashmi.n (Jul 31, 2025, 9:15:32 PM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
